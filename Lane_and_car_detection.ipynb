{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwLRQ5IF0Q1z",
        "outputId": "1d1c690f-814f-433a-91be-5cd8e72e15d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2605056/45929032 bytes (5.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5677056/45929032 bytes (12.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b8536064/45929032 bytes (18.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b11550720/45929032 bytes (25.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b14155776/45929032 bytes (30.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16850944/45929032 bytes (36.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b19652608/45929032 bytes (42.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b22650880/45929032 bytes (49.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b25665536/45929032 bytes (55.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b28696576/45929032 bytes (62.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b31596544/45929032 bytes (68.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b34594816/45929032 bytes (75.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b37642240/45929032 bytes (82.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b40501248/45929032 bytes (88.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b43155456/45929032 bytes (94.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pylab\n",
        "from google.colab.patches import cv2_imshow\n",
        "from moviepy.editor import VideoFileClip\n",
        "from moviepy import *\n",
        "%matplotlib inline\n",
        "import time\n",
        "import os\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4li9AMK40fnH"
      },
      "outputs": [],
      "source": [
        "def region_of_interest(img, vertices):\n",
        "    mask = np.zeros_like(img)\n",
        "    #channel_count = img.shape[2]\n",
        "    match_mask_color = 255\n",
        "    cv2.fillPoly(mask, vertices, match_mask_color)\n",
        "    masked_image = cv2.bitwise_and(img, mask)\n",
        "    return masked_image\n",
        "\n",
        "\n",
        "def drow_the_lines(img, lines):\n",
        "    img = np.copy(img)\n",
        "    blank_image = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
        "\n",
        "    for line in lines:\n",
        "        for x1, y1, x2, y2 in line:\n",
        "            cv2.line(blank_image, (x1,y1), (x2,y2), (0, 255, 0), thickness=10)\n",
        "\n",
        "    img = cv2.addWeighted(img, 1, blank_image, 1, 0.0)\n",
        "    return img, blank_image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQn9tgBi0rsc"
      },
      "outputs": [],
      "source": [
        "def paint (img,vertices):\n",
        "  mask = np.zeros_like(img)\n",
        "  channel_count = img.shape[2]\n",
        "  cv2.fillPoly(mask, vertices, color=(0, 255, 255))\n",
        "  return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiL_Lrso0vST"
      },
      "outputs": [],
      "source": [
        "def get_car_position(x_min,w):\n",
        "    xm_per_pix=3.7/720\n",
        "    if x_min is not None:\n",
        "        car_position = w/2\n",
        "        lane_center_position = (x_min+(700/2))\n",
        "        center_dist = (car_position - lane_center_position) * xm_per_pix\n",
        "    \n",
        "    return center_dist \n",
        "def get_direction(center_dist):\n",
        "    direction = ''\n",
        "    if center_dist > 0:\n",
        "        direction = 'right'\n",
        "    elif center_dist < 0:\n",
        "        direction = 'left'\n",
        "    return direction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwwpUpMD0yyp"
      },
      "outputs": [],
      "source": [
        "def write_on_image (img,x_min) :\n",
        "  font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
        "  text1=get_car_position(x_min,1280)\n",
        "  direction=get_direction(text1)\n",
        "  text=abs(get_car_position(x_min,1280))\n",
        "  text = '{:04.3f}'.format(text) + 'm ' + direction + ' of center'\n",
        "  edited_photo=cv2.putText(img, text,(40,70), cv2.FONT_HERSHEY_COMPLEX_SMALL,1.5,(255,255,255),2,cv2.LINE_AA)\n",
        "  return edited_photo;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEs7OqB16PEO"
      },
      "source": [
        "### phase 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yEZXpnj6X_6"
      },
      "source": [
        "### Load weights and cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmZNNiab6Yg6"
      },
      "outputs": [],
      "source": [
        "weights_path =os.path.join(\"yolov3.weights\")\n",
        "cfg_path =os.path.join(\"yolov3.cfg.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7VQDMZR6cl2"
      },
      "source": [
        "### load neural net in cv2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rC_yX7w6grq"
      },
      "outputs": [],
      "source": [
        "net=cv2.dnn.readNetFromDarknet(cfg_path,weights_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFSbMYTw6loj"
      },
      "outputs": [],
      "source": [
        "names=net.getLayerNames() #get layers name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0da0L9V6mBa"
      },
      "outputs": [],
      "source": [
        "layers_names=[names[i[0] - 1] for i in net.getUnconnectedOutLayers()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0otySe06oHB"
      },
      "outputs": [],
      "source": [
        "labels_path=os.path.join (\"coco.names.txt\")\n",
        "labels = open(labels_path).read().strip().split(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iilLqeU06qSd"
      },
      "outputs": [],
      "source": [
        "def process(image):\n",
        "  #print(image.shape)\n",
        "  region_of_interest_vertices = [\n",
        "    (200, 665),\n",
        "    (620,410),\n",
        "    (1130, 665)\n",
        "  ]\n",
        "  hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
        "  #h_channel=hls[:,:,0]\n",
        "  #l_channel=hls[:,:,1]\n",
        "  s_channel=hls[:,:,2]\n",
        "  canny_image = cv2.Canny(s_channel, 100, 200)\n",
        "  cropped_image = region_of_interest(canny_image,\n",
        "                np.array([region_of_interest_vertices], np.int32))\n",
        "\n",
        "  lines = cv2.HoughLinesP(cropped_image,\n",
        "                        rho=6,\n",
        "                        theta=np.pi/180,\n",
        "                        threshold=160,\n",
        "                        lines=np.array([]),\n",
        "                        minLineLength=40,\n",
        "                        maxLineGap=25)\n",
        "  try :\n",
        "    image_with_lines , mask = drow_the_lines(image, lines)\n",
        "    c = (0,255,0)\n",
        "    indices = np.where(np.all(mask == c, axis=-1))\n",
        "    x_min=np.min(indices[1])\n",
        "    if x_min<285 or x_min is None :\n",
        "      x_min=285\n",
        "    y_max=np.max(indices[0])\n",
        "    x_topleft=x_min+310\n",
        "    y_min=np.min(indices[0])\n",
        "    if y_min<450 or y_min is None :\n",
        "      y_min=450\n",
        "  except:\n",
        "      image_with_lines=image\n",
        "      x_min=285\n",
        "      x_topleft=660\n",
        "      y_min=500\n",
        "      y_max=670\n",
        "  vertices_paint = [\n",
        "    (x_min,y_max),\n",
        "    (x_topleft,y_min),\n",
        "    (x_topleft+45,y_min),\n",
        "    (x_min+720, y_max)\n",
        "  ]\n",
        "  yellow_rec=paint(image,np.array([vertices_paint], np.int32))\n",
        "  last_image = cv2.addWeighted(image_with_lines, 0.8, yellow_rec, 1, 0.0)\n",
        "  last_edited=write_on_image (last_image,x_min)\n",
        "  blob= cv2.dnn.blobFromImage(last_edited,1/255.0,(416,416),crop=False,swapRB=False)\n",
        "  net.setInput(blob)\n",
        "  layers_output=net.forward(layers_names)\n",
        "  (H,W)=last_edited.shape[:2]\n",
        "  boxes=[]\n",
        "  confidences=[]\n",
        "  classIDs=[]\n",
        "  for output in layers_output:\n",
        "    for detection in output:\n",
        "        scores=detection[5:]\n",
        "        classID=np.argmax(scores)\n",
        "        confidence=scores[classID]\n",
        "        \n",
        "        if (confidence >0.85):\n",
        "            box=detection[:4] * np.array([W,H,W,H])\n",
        "            bx,by,bw,bh=box.astype(\"int\")\n",
        "            \n",
        "            x=int(bx-(bw/2))\n",
        "            y=int(by-(bh/2))\n",
        "           \n",
        "            boxes.append([x,y,int(bw),int(bh)])\n",
        "            confidences.append(float(confidence))\n",
        "            classIDs.append(classID)\n",
        "    idx=cv2.dnn.NMSBoxes(boxes,confidences,0.8,0.8)\n",
        "    if (len(idx)>0):\n",
        "        for i in idx.flatten():\n",
        "            (x,y)=[boxes[i][0],boxes[i][1]]\n",
        "            (w,h)=[boxes[i][2],boxes[i][3]]\n",
        "        cv2.rectangle (last_edited,(x,y),(x+w ,y+h),(0,139,139),2)\n",
        "        cv2.putText(last_edited,\"{}:{}\".format(labels[classIDs[i]],confidences[i]),(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,139,139),2)\n",
        "  return last_edited\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJ7GBpdM645T",
        "outputId": "3e2cde5f-f681-4683-c4cf-9d5b63510087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] >>>> Building video challenge_video_merged_full.mp4\n",
            "[MoviePy] Writing video challenge_video_merged_full.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 485/485 [10:58<00:00,  1.36s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] >>>> Video ready: challenge_video_merged_full.mp4 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "white_output = (\"challenge_video_merged_full.mp4\")\n",
        "clip1 = VideoFileClip(\"challenge_video.mp4\") \n",
        "white_clip = clip1.fl_image(process)\n",
        "white_clip.write_videofile(white_output, audio=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Sm6iMp6-yqO"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Lane_and_car_detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}